
As an AutoML Agent, you will be given a folder containing data and description files. Please generate Python code using autogluon.tabular to train a predictor and make predictions on test data. Follow these specifications:

ONLY save files to the working directory: /opt/dlami/nvme/autogluon-assistant/output.

1. Data preprocessing:
   - Remove training data samples without valid labels (drop NA values from training dataset ONLY, NOT from test dataset) unless explicitly instructed otherwise.
   - Remove the unneccesary index column (if applicable)

2. Model training:
   - Use autogluon.tabular with appropriate parameters for the task
   - If a model is trained, save it in a folder with random timestamp within /opt/dlami/nvme/autogluon-assistant/output

3. Prediction:
   - Make predictions on the test data
   - Save the predicted results to /opt/dlami/nvme/autogluon-assistant/output, result file name should be "results", the format and extension should be same as the test data file
   - Output column names must exactly match those in the training or sample submission files without adding "predicted_" prefixes or creating any new columns.

4. Documentation:
   - Add a brief docstring at the beginning of the script explaining its purpose and usage
   - Also include additional installation steps with comments at the beginning of the script
   - Include comments explaining any complex operations or design decisions

5. Others:
   - To avoid DDP errors, wrap the code in: if __name__ == "__main__":
   - Ensure errors are propagated up and not silently caught - do not use try/except blocks unless you explicitly re-raise the exception.

Use Autogluon Tabular with the following parameters:
- time_limit: 1800 seconds
- presets: \"medium_quality\"
- tuning_data: only use validation if there is a validation dataset.
- problem_type: binary, multiclass, or regression.
IMPORTANT: To handle multi-label classification/regression with AutoGluon, split the problem by training a separate model for each label column (whether binary or multiclass) using the same feature set (EXCLUDE other label columns!) but different target columns, then combine predictions from all models to form the complete multi-label output for new data.

Please provide the complete Python script that accomplishes these tasks, ensuring it's ready to run given the appropriate data inputs.

Task Description: # Data Science Task Description

Based solely on the provided information, the data science task is:

**Objective**: Predict the price category (price_label) of Airbnb listings in Melbourne, where the price_label represents the price range into which a listing falls after being grouped into distinct bins.

**Data Available**:
- Training data (`train.pq`, 30.50 MB) containing Airbnb listing information
- Inference data (`inference.pq`, 7.43 MB) for making predictions

**Data Structure**:
- Both datasets contain numerous columns including listing details (name, summary, space, description), neighborhood information, and host verification data
- The training data has 90 columns while the inference data has 89 columns

The task appears to be a classification problem where the model needs to categorize Airbnb listings into predefined price range bins based on the available features.
